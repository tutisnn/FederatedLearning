{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install nvflare torch torchvision tensorboard opacus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T17:42:27.479950Z",
     "iopub.status.busy": "2025-10-26T17:42:27.479698Z",
     "iopub.status.idle": "2025-10-26T17:42:28.489828Z",
     "shell.execute_reply": "2025-10-26T17:42:28.488973Z",
     "shell.execute_reply.started": "2025-10-26T17:42:27.479931Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: /tmp/nvflare/data\n",
       "    Split: Train"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision\n",
    "DATASET_PATH = \"/tmp/nvflare/data\"\n",
    "torchvision.datasets.CIFAR10(root=DATASET_PATH, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T17:42:50.883306Z",
     "iopub.status.busy": "2025-10-26T17:42:50.882906Z",
     "iopub.status.idle": "2025-10-26T17:42:51.035104Z",
     "shell.execute_reply": "2025-10-26T17:42:51.033929Z",
     "shell.execute_reply.started": "2025-10-26T17:42:50.883277Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘src’: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T17:42:53.048230Z",
     "iopub.status.busy": "2025-10-26T17:42:53.047760Z",
     "iopub.status.idle": "2025-10-26T17:42:53.056732Z",
     "shell.execute_reply": "2025-10-26T17:42:53.055570Z",
     "shell.execute_reply.started": "2025-10-26T17:42:53.048192Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/net.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/net.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.dopout = nn.Dropout(0.1) # Orjinaldeki typo'yu korudum, 'dropout' olabilir\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = self.dopout(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dopout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dopout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T17:43:10.422308Z",
     "iopub.status.busy": "2025-10-26T17:43:10.421936Z",
     "iopub.status.idle": "2025-10-26T17:43:10.430502Z",
     "shell.execute_reply": "2025-10-26T17:43:10.429549Z",
     "shell.execute_reply.started": "2025-10-26T17:43:10.422282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nvflare.app_common.workflows.fedavg import FedAvg\n",
    "from nvflare.app_opt.pt.job_config.base_fed_job import BaseFedJob\n",
    "from nvflare.job_config.script_runner import ScriptRunner\n",
    "from src.net import Net\n",
    "\n",
    "job = BaseFedJob(\n",
    "    name=\"cifar10_fedavg\",\n",
    "    initial_model=Net(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T17:43:12.982286Z",
     "iopub.status.busy": "2025-10-26T17:43:12.981804Z",
     "iopub.status.idle": "2025-10-26T17:43:12.987385Z",
     "shell.execute_reply": "2025-10-26T17:43:12.986313Z",
     "shell.execute_reply.started": "2025-10-26T17:43:12.982260Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "n_clients = 2\n",
    "\n",
    "controller = FedAvg(\n",
    "    num_clients=n_clients,\n",
    "    num_rounds=3,  # 30 rounds should converge\n",
    ")\n",
    "job.to(controller, \"server\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T17:43:18.324364Z",
     "iopub.status.busy": "2025-10-26T17:43:18.323619Z",
     "iopub.status.idle": "2025-10-26T17:43:18.335424Z",
     "shell.execute_reply": "2025-10-26T17:43:18.334403Z",
     "shell.execute_reply.started": "2025-10-26T17:43:18.324314Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/cifar10_fl.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile src/cifar10_fl.py\n",
    "# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F # Added for Net class\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from net import Net # Removed this import\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "# (1) import nvflare client API\n",
    "import nvflare.client as flare\n",
    "\n",
    "# (optional) metrics\n",
    "from nvflare.client.tracking import SummaryWriter\n",
    "\n",
    "\n",
    "# (optional) set a fix place so we don't need to download everytime\n",
    "DATASET_PATH = \"/tmp/nvflare/data\"\n",
    "# If available, we use GPU to speed things up.\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Running on device {DEVICE}\")\n",
    "\n",
    "\n",
    "def main(target_epsilon, max_grad_norm):\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    batch_size = 32\n",
    "    epochs = 1\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=True, download=True, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root=DATASET_PATH, train=False, download=True, transform=transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    net = Net() # Now uses the class defined above\n",
    "\n",
    "    # (2) initializes NVFlare client API\n",
    "    flare.init()\n",
    "\n",
    "    # (Optional) compute unique seed from client name to initialize data loaders\n",
    "    client_name = flare.get_site_name()\n",
    "    seed = int.from_bytes(client_name.encode(), \"big\")\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    # Optionally add DP engine\n",
    "    if target_epsilon:\n",
    "        target_delta = 1e-5\n",
    "        print(f\"Adding privacy engine with epsilon={target_epsilon}, delta={target_delta}\")\n",
    "        privacy_engine = PrivacyEngine()\n",
    "        # Need to handle potential .receive() call here for total_rounds if flare is initialized\n",
    "        # Assuming flare.init() might not fully initialize context outside main loop start\n",
    "        # A placeholder or default value might be needed, or refactor to get total_rounds later.\n",
    "        # For simplicity, let's assume total_rounds can be accessed or estimated.\n",
    "        # A robust solution might require fetching total_rounds differently or setting a high default.\n",
    "        estimated_total_rounds = 10 # Example placeholder, adjust as needed\n",
    "        total_epochs_for_dp = epochs * estimated_total_rounds \n",
    "\n",
    "        net, optimizer, trainloader = privacy_engine.make_private_with_epsilon(\n",
    "            module=net,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=trainloader,\n",
    "            target_epsilon=target_epsilon,\n",
    "            target_delta=target_delta,\n",
    "            epochs=total_epochs_for_dp, # Use estimated total epochs\n",
    "            max_grad_norm=max_grad_norm,\n",
    "        )\n",
    "\n",
    "    summary_writer = SummaryWriter()\n",
    "    first_round = True # Flag to potentially recalculate DP epochs if needed\n",
    "\n",
    "    while flare.is_running():\n",
    "        # (3) receives FLModel from NVFlare\n",
    "        input_model = flare.receive()\n",
    "        print(f\"current_round={input_model.current_round}, total_rounds={input_model.total_rounds}\")\n",
    "\n",
    "        # If DP is enabled and it's the first round, potentially re-attach DP engine with correct total_rounds\n",
    "        if target_epsilon and first_round and hasattr(privacy_engine, 'steps'):\n",
    "            print(\"Re-calculating DP parameters based on received total_rounds.\")\n",
    "            # Detach existing engine if possible (Opacus API might vary)\n",
    "            # This part is complex as Opacus doesn't easily support dynamic epoch changes after make_private\n",
    "            # A simpler approach might be to accept the initial estimate or require total_rounds upfront\n",
    "            # For this example, we'll proceed with the initial estimate.\n",
    "            # A more advanced implementation might involve custom Accountant or careful state management.\n",
    "            pass # Sticking with initial DP setup for simplicity in this example\n",
    "        first_round = False\n",
    "\n",
    "\n",
    "        # (4) loads model from NVFlare\n",
    "        if target_epsilon and hasattr(net, '_module'): # Check if Opacus wrapped the model\n",
    "            global_params = {}\n",
    "            for k, v in input_model.params.items():\n",
    "                global_params[f\"_module.{k}\"] = v\n",
    "        else:\n",
    "            global_params = input_model.params\n",
    "        \n",
    "        try:\n",
    "             net.load_state_dict(global_params)\n",
    "        except RuntimeError as e:\n",
    "             print(f\"Error loading state dict: {e}\")\n",
    "             print(\"Possibly due to DP wrapper mismatch. Trying to load into underlying module if DP enabled.\")\n",
    "             if target_epsilon and hasattr(net, '_module'):\n",
    "                  # Try loading directly into the wrapped module if keys match input_model.params\n",
    "                  try:\n",
    "                      net._module.load_state_dict(input_model.params)\n",
    "                      print(\"Loaded state dict into underlying module.\")\n",
    "                  except Exception as inner_e:\n",
    "                      print(f\"Failed loading into underlying module as well: {inner_e}\")\n",
    "                      # Handle error appropriately, maybe skip round or raise\n",
    "             else:\n",
    "                  # If not DP or loading underlying failed, re-raise or handle\n",
    "                  raise e\n",
    "\n",
    "\n",
    "        net.to(DEVICE)\n",
    "        net.train()\n",
    "        steps = epochs * len(trainloader)\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print(f\"[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 100:.3f}\")\n",
    "                    global_step = input_model.current_round * steps + epoch * len(trainloader) + i\n",
    "\n",
    "                    summary_writer.add_scalar(\n",
    "                        tag=\"loss_for_each_batch\", scalar=running_loss / 100, global_step=global_step\n",
    "                    )\n",
    "                    running_loss = 0.0\n",
    "\n",
    "                    if target_epsilon and hasattr(privacy_engine, 'get_epsilon'):\n",
    "                        epsilon = privacy_engine.get_epsilon(target_delta)\n",
    "                        print(f\"Training with privacy (ε = {epsilon:.2f}, δ = {target_delta})\")\n",
    "\n",
    "        print(\"Finished Training\")\n",
    "\n",
    "        PATH = \"./cifar_net.pth\"\n",
    "        torch.save(net.state_dict(), PATH)\n",
    "\n",
    "        def evaluate(input_weights):\n",
    "            eval_net = Net() # Use the class defined in this file\n",
    "            # Adjust keys if loading a DP-modified global model for evaluation\n",
    "            if target_epsilon and any(k.startswith(\"_module.\") for k in input_weights.keys()):\n",
    "                 # If global model has DP prefix, load into DP-wrapped structure or strip prefix\n",
    "                 # Simpler: strip prefix for evaluation if eval_net isn't DP-wrapped\n",
    "                 eval_weights_adjusted = {k.replace(\"_module.\", \"\"): v for k, v in input_weights.items()}\n",
    "                 eval_net.load_state_dict(eval_weights_adjusted)\n",
    "\n",
    "            elif target_epsilon and not any(k.startswith(\"_module.\") for k in input_weights.keys()):\n",
    "                 # DP client evaluating non-DP global model? Might happen depending on FL setup.\n",
    "                 # Load directly.\n",
    "                 eval_net.load_state_dict(input_weights)\n",
    "            else:\n",
    "                 # Non-DP case\n",
    "                 eval_net.load_state_dict(input_weights)\n",
    "\n",
    "            eval_net.to(DEVICE)\n",
    "            eval_net.eval()\n",
    "\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in testloader:\n",
    "                    images, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    outputs = eval_net(images)\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "\n",
    "            accuracy = 100 * correct / total # Use floating point division for accuracy\n",
    "            print(f\"Accuracy of the network on the 10000 test images: {accuracy:.2f} %\")\n",
    "            return accuracy # Return float accuracy\n",
    "\n",
    "        # Evaluate potentially DP-modified global model\n",
    "        accuracy = evaluate(input_model.params)\n",
    "        summary_writer.add_scalar(tag=\"global_model_accuracy\", scalar=accuracy, global_step=input_model.current_round)\n",
    "        \n",
    "        # Prepare local model parameters for sending back\n",
    "        net.cpu() # Move model to CPU before getting state_dict\n",
    "        if target_epsilon and hasattr(net, '_module'):\n",
    "            local_params = {}\n",
    "            # Get state_dict from the original module wrapped by Opacus\n",
    "            for k, v in net._module.state_dict().items():\n",
    "                local_params[k] = v # Use original keys without \"_module.\"\n",
    "        else:\n",
    "            local_params = net.state_dict()\n",
    "\n",
    "        output_model = flare.FLModel(\n",
    "            params=local_params,\n",
    "            metrics={\"accuracy\": accuracy}, # Sending float accuracy\n",
    "            meta={\"NUM_STEPS_CURRENT_ROUND\": steps},\n",
    "        )\n",
    "        flare.send(output_model)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--target_epsilon\", type=float, default=None, help=\"Target epsilon for DP training. If None, DP is disabled.\")\n",
    "    parser.add_argument(\"--max_grad_norm\", type=float, default=1.0, help=\"Max grad norm for DP training.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Create src directory if it doesn't exist (useful if running %%writefile in a clean env)\n",
    "    import os\n",
    "    os.makedirs(\"src\", exist_ok=True)\n",
    "\n",
    "    main(target_epsilon=args.target_epsilon, max_grad_norm=args.max_grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T17:43:24.163092Z",
     "iopub.status.busy": "2025-10-26T17:43:24.162239Z",
     "iopub.status.idle": "2025-10-26T17:43:24.169262Z",
     "shell.execute_reply": "2025-10-26T17:43:24.168458Z",
     "shell.execute_reply.started": "2025-10-26T17:43:24.163021Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in range(n_clients):\n",
    "    runner = ScriptRunner(\n",
    "        script=\"src/cifar10_fl.py\"\n",
    "    )\n",
    "    job.to(runner, f\"site-{i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T17:43:27.497758Z",
     "iopub.status.busy": "2025-10-26T17:43:27.496977Z",
     "iopub.status.idle": "2025-10-26T17:46:17.776295Z",
     "shell.execute_reply": "2025-10-26T17:46:17.774939Z",
     "shell.execute_reply.started": "2025-10-26T17:43:27.497724Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38m2025-10-26 17:43:29,269 - INFO - model selection weights control: {}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 17:43:32.480406: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761500612.530859     289 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761500612.548070     289 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38m2025-10-26 17:43:37,666 - INFO - Tensorboard records can be found in /tmp/nvflare/cifar10_fedavg/server/simulate_job/tb_events you can view it using `tensorboard --logdir=/tmp/nvflare/cifar10_fedavg/server/simulate_job/tb_events`\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:37,669 - INFO - Initializing BaseModelController workflow.\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:37,670 - INFO - Beginning model controller run.\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:37,671 - INFO - \n",
      "================================================================================\n",
      "                                 Start FedAvg.                                  \n",
      "================================================================================\n",
      "\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:37,671 - INFO - loading initial model from persistor\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:37,672 - INFO - Both source_ckpt_file_full_name and ckpt_preload_path are not provided. Using the default model weights initialized on the persistor side.\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:37,673 - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "                                Round 0 started.                                \n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:37,674 - INFO - Sampled clients: ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:37,674 - INFO - Sending task train to ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:42,887 - INFO - start task run() with full path: /tmp/nvflare/cifar10_fedavg/site-2/simulate_job/app_site-2/custom/src/cifar10_fl.py\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:42,921 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:42,922 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:42,923 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:42,925 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:43,021 - INFO - start task run() with full path: /tmp/nvflare/cifar10_fedavg/site-1/simulate_job/app_site-1/custom/src/cifar10_fl.py\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:43,056 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:43,057 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:43,058 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:43,060 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:45,514 - INFO - Running on device cpu\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:45,514 - INFO - Running on device cpu\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:47,775 - INFO - current_round=0, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:47,786 - INFO - current_round=0, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:50,500 - INFO - [1,   100] loss: 2.300\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:50,693 - INFO - [1,   100] loss: 2.300\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:52,907 - INFO - [1,   200] loss: 2.180\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:53,199 - INFO - [1,   200] loss: 2.179\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:55,185 - INFO - [1,   300] loss: 2.010\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:55,594 - INFO - [1,   300] loss: 2.011\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:57,774 - INFO - [1,   400] loss: 1.896\u001b[0m\n",
      "\u001b[38m2025-10-26 17:43:58,096 - INFO - [1,   400] loss: 1.912\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:00,378 - INFO - [1,   500] loss: 1.813\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:00,485 - INFO - [1,   500] loss: 1.834\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:02,732 - INFO - [1,   600] loss: 1.781\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:02,921 - INFO - [1,   600] loss: 1.739\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:05,258 - INFO - [1,   700] loss: 1.697\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:05,520 - INFO - [1,   700] loss: 1.723\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:07,715 - INFO - [1,   800] loss: 1.660\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:07,948 - INFO - [1,   800] loss: 1.701\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:10,217 - INFO - [1,   900] loss: 1.630\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:10,459 - INFO - [1,   900] loss: 1.646\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:12,800 - INFO - [1,  1000] loss: 1.590\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:12,883 - INFO - [1,  1000] loss: 1.607\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:15,172 - INFO - [1,  1100] loss: 1.598\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:15,371 - INFO - [1,  1100] loss: 1.614\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:17,600 - INFO - [1,  1200] loss: 1.544\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:17,822 - INFO - [1,  1200] loss: 1.541\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:19,895 - INFO - [1,  1300] loss: 1.532\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:20,364 - INFO - [1,  1300] loss: 1.520\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:22,243 - INFO - [1,  1400] loss: 1.541\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:22,880 - INFO - [1,  1400] loss: 1.550\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:24,521 - INFO - [1,  1500] loss: 1.525\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:25,464 - INFO - [1,  1500] loss: 1.501\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:26,176 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:26,878 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:31,765 - INFO - Accuracy of the network on the 10000 test images: 10.02 %\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:32,148 - INFO - Accuracy of the network on the 10000 test images: 10.02 %\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:33,156 - INFO - aggregating 2 update(s) at round 0\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:33,158 - INFO - Start persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:33,161 - INFO - End persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:33,162 - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "                                Round 1 started.                                \n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:33,163 - INFO - Sampled clients: ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:33,163 - INFO - Sending task train to ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:34,645 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:34,645 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:34,646 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:34,647 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:34,776 - INFO - current_round=1, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:34,980 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:34,982 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:34,983 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:34,984 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:35,157 - INFO - current_round=1, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:37,007 - INFO - [1,   100] loss: 1.472\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:37,750 - INFO - [1,   100] loss: 1.489\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:39,506 - INFO - [1,   200] loss: 1.481\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:40,156 - INFO - [1,   200] loss: 1.437\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:42,101 - INFO - [1,   300] loss: 1.464\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:42,557 - INFO - [1,   300] loss: 1.488\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:44,715 - INFO - [1,   400] loss: 1.422\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:44,859 - INFO - [1,   400] loss: 1.441\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:47,464 - INFO - [1,   500] loss: 1.399\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:47,485 - INFO - [1,   500] loss: 1.434\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:49,837 - INFO - [1,   600] loss: 1.412\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:50,059 - INFO - [1,   600] loss: 1.444\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:52,273 - INFO - [1,   700] loss: 1.400\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:52,582 - INFO - [1,   700] loss: 1.415\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:54,677 - INFO - [1,   800] loss: 1.374\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:54,944 - INFO - [1,   800] loss: 1.390\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:57,284 - INFO - [1,   900] loss: 1.376\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:57,314 - INFO - [1,   900] loss: 1.375\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:59,515 - INFO - [1,  1000] loss: 1.368\u001b[0m\n",
      "\u001b[38m2025-10-26 17:44:59,685 - INFO - [1,  1000] loss: 1.381\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:01,889 - INFO - [1,  1100] loss: 1.384\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:02,064 - INFO - [1,  1100] loss: 1.337\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:04,486 - INFO - [1,  1200] loss: 1.346\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:04,505 - INFO - [1,  1200] loss: 1.369\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:06,916 - INFO - [1,  1300] loss: 1.346\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:07,214 - INFO - [1,  1300] loss: 1.379\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:09,494 - INFO - [1,  1400] loss: 1.334\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:09,732 - INFO - [1,  1400] loss: 1.338\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:11,744 - INFO - [1,  1500] loss: 1.316\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:12,414 - INFO - [1,  1500] loss: 1.354\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:13,101 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:13,881 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:19,110 - INFO - Accuracy of the network on the 10000 test images: 48.34 %\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:19,402 - INFO - Accuracy of the network on the 10000 test images: 48.34 %\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:19,559 - INFO - validation metric 48.34 from client site-2\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:19,865 - INFO - validation metric 48.34 from client site-1\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:20,342 - INFO - new best validation metric at round 1: 48.34\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:20,346 - INFO - aggregating 2 update(s) at round 1\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:20,348 - INFO - Start persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:20,350 - INFO - End persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:20,351 - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "                                Round 2 started.                                \n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:20,351 - INFO - Sampled clients: ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:20,352 - INFO - Sending task train to ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:21,869 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:21,870 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:21,871 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:21,872 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:22,119 - INFO - current_round=2, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:22,162 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:22,164 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:22,165 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:22,167 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:22,411 - INFO - current_round=2, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:24,498 - INFO - [1,   100] loss: 1.305\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:25,053 - INFO - [1,   100] loss: 1.288\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:27,503 - INFO - [1,   200] loss: 1.286\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:27,671 - INFO - [1,   200] loss: 1.282\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:29,948 - INFO - [1,   300] loss: 1.287\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:30,193 - INFO - [1,   300] loss: 1.275\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:32,477 - INFO - [1,   400] loss: 1.283\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:32,753 - INFO - [1,   400] loss: 1.249\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:35,020 - INFO - [1,   500] loss: 1.303\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:35,386 - INFO - [1,   500] loss: 1.265\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:37,661 - INFO - [1,   600] loss: 1.256\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:37,838 - INFO - [1,   600] loss: 1.276\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:40,056 - INFO - [1,   700] loss: 1.269\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:40,450 - INFO - [1,   700] loss: 1.326\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:42,600 - INFO - [1,   800] loss: 1.308\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:42,858 - INFO - [1,   800] loss: 1.310\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:45,008 - INFO - [1,   900] loss: 1.273\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:45,233 - INFO - [1,   900] loss: 1.309\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:47,413 - INFO - [1,  1000] loss: 1.287\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:47,820 - INFO - [1,  1000] loss: 1.259\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:49,849 - INFO - [1,  1100] loss: 1.237\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:50,114 - INFO - [1,  1100] loss: 1.270\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:52,406 - INFO - [1,  1200] loss: 1.277\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:52,604 - INFO - [1,  1200] loss: 1.253\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:54,900 - INFO - [1,  1300] loss: 1.275\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:55,005 - INFO - [1,  1300] loss: 1.240\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:57,397 - INFO - [1,  1400] loss: 1.260\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:57,570 - INFO - [1,  1400] loss: 1.265\u001b[0m\n",
      "\u001b[38m2025-10-26 17:45:59,813 - INFO - [1,  1500] loss: 1.260\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:00,062 - INFO - [1,  1500] loss: 1.261\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:01,498 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:01,601 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:07,038 - INFO - Accuracy of the network on the 10000 test images: 55.84 %\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:07,439 - INFO - validation metric 55.84 from client site-2\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:07,470 - INFO - Accuracy of the network on the 10000 test images: 55.84 %\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:07,747 - INFO - validation metric 55.84 from client site-1\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:08,225 - INFO - new best validation metric at round 2: 55.84\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:08,230 - INFO - aggregating 2 update(s) at round 2\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:08,231 - INFO - Start persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:08,234 - INFO - End persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 17:46:08,235 - INFO - \n",
      "================================================================================\n",
      "                                Finished FedAvg.                                \n",
      "================================================================================\n",
      "\u001b[0m\n",
      "\u001b[33m2025-10-26 17:46:09,750 - WARNING - ask to stop job: reason: END_RUN received\u001b[0m\n",
      "\u001b[33m2025-10-26 17:46:10,040 - WARNING - ask to stop job: reason: END_RUN received\u001b[0m\n",
      "\u001b[33m2025-10-26 17:46:10,053 - WARNING - request to stop the job for reason END_RUN received\u001b[0m\n",
      "\u001b[33m2025-10-26 17:46:10,479 - WARNING - request to stop the job for reason END_RUN received\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "job.simulator_run(f\"/tmp/nvflare/{job.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add DP as an NVFlare Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T18:01:14.469664Z",
     "iopub.status.busy": "2025-10-26T18:01:14.469327Z",
     "iopub.status.idle": "2025-10-26T18:01:14.494979Z",
     "shell.execute_reply": "2025-10-26T18:01:14.494210Z",
     "shell.execute_reply.started": "2025-10-26T18:01:14.469644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nvflare import FilterType\n",
    "from nvflare.client.config import TransferType\n",
    "from nvflare.app_common.filters import SVTPrivacy\n",
    "\n",
    "# Create BaseFedJob with the initial model\n",
    "job = BaseFedJob(\n",
    "  name=\"cifar10_fedavg_dp\",\n",
    "  initial_model=Net(),\n",
    ")\n",
    "\n",
    "# Define the controller and send to server\n",
    "controller = FedAvg(\n",
    "    num_clients=n_clients,\n",
    "    num_rounds=3,  # 100 rounds should converge\n",
    ")\n",
    "job.to_server(controller)\n",
    "\n",
    "# Add clients\n",
    "for i in range(n_clients):\n",
    "    runner = ScriptRunner(\n",
    "        script=\"src/cifar10_fl.py\",\n",
    "        params_transfer_type=TransferType.DIFF\n",
    "    )\n",
    "    job.to(runner, f\"site-{i+1}\")\n",
    "\n",
    "    # add privacy filter.\n",
    "    dp_filter = SVTPrivacy(fraction=0.9, epsilon=0.1, noise_var=0.1, gamma=1e-5)\n",
    "    job.to(dp_filter, f\"site-{i+1}\", tasks=[\"train\"], filter_type=FilterType.TASK_RESULT)\n",
    "\n",
    "# Optionally export the configuration\n",
    "job.export_job(\"job_configs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T18:01:41.051350Z",
     "iopub.status.busy": "2025-10-26T18:01:41.050945Z",
     "iopub.status.idle": "2025-10-26T18:04:28.517786Z",
     "shell.execute_reply": "2025-10-26T18:04:28.516555Z",
     "shell.execute_reply.started": "2025-10-26T18:01:41.051319Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38m2025-10-26 18:01:42,583 - INFO - model selection weights control: {}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-26 18:01:45.850046: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761501705.898844     589 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761501705.914501     589 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py\", line 42, in tf\n",
      "    from tensorboard.compat import notf  # noqa: F401\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "ImportError: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.11/dist-packages/tensorboard/compat/__init__.py)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "AttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38m2025-10-26 18:01:51,004 - INFO - Tensorboard records can be found in /tmp/nvflare/cifar10_fedavg_dp/server/simulate_job/tb_events you can view it using `tensorboard --logdir=/tmp/nvflare/cifar10_fedavg_dp/server/simulate_job/tb_events`\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:51,006 - INFO - Initializing BaseModelController workflow.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:51,007 - INFO - Beginning model controller run.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:51,008 - INFO - \n",
      "================================================================================\n",
      "                                 Start FedAvg.                                  \n",
      "================================================================================\n",
      "\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:51,008 - INFO - loading initial model from persistor\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:51,009 - INFO - Both source_ckpt_file_full_name and ckpt_preload_path are not provided. Using the default model weights initialized on the persistor side.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:51,010 - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "                                Round 0 started.                                \n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:51,011 - INFO - Sampled clients: ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:51,011 - INFO - Sending task train to ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:56,447 - INFO - start task run() with full path: /tmp/nvflare/cifar10_fedavg_dp/site-2/simulate_job/app_site-2/custom/src/cifar10_fl.py\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:56,479 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:56,480 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:56,481 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:56,482 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:56,505 - INFO - start task run() with full path: /tmp/nvflare/cifar10_fedavg_dp/site-1/simulate_job/app_site-1/custom/src/cifar10_fl.py\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:56,537 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:56,541 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:56,542 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:56,544 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:58,790 - INFO - Running on device cpu\u001b[0m\n",
      "\u001b[38m2025-10-26 18:01:58,860 - INFO - Running on device cpu\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:01,246 - INFO - current_round=0, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:01,326 - INFO - current_round=0, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:03,739 - INFO - [1,   100] loss: 2.297\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:03,853 - INFO - [1,   100] loss: 2.295\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:06,199 - INFO - [1,   200] loss: 2.141\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:06,672 - INFO - [1,   200] loss: 2.125\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:08,499 - INFO - [1,   300] loss: 1.996\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:08,946 - INFO - [1,   300] loss: 1.985\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:10,860 - INFO - [1,   400] loss: 1.876\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:11,169 - INFO - [1,   400] loss: 1.873\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:13,211 - INFO - [1,   500] loss: 1.780\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:13,443 - INFO - [1,   500] loss: 1.794\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:15,737 - INFO - [1,   600] loss: 1.726\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:15,905 - INFO - [1,   600] loss: 1.742\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:18,375 - INFO - [1,   700] loss: 1.666\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:18,467 - INFO - [1,   700] loss: 1.697\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:20,743 - INFO - [1,   800] loss: 1.634\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:21,071 - INFO - [1,   800] loss: 1.686\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:23,025 - INFO - [1,   900] loss: 1.616\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:23,400 - INFO - [1,   900] loss: 1.619\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:25,689 - INFO - [1,  1000] loss: 1.568\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:25,926 - INFO - [1,  1000] loss: 1.604\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:28,120 - INFO - [1,  1100] loss: 1.594\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:28,482 - INFO - [1,  1100] loss: 1.611\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:30,570 - INFO - [1,  1200] loss: 1.548\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:30,857 - INFO - [1,  1200] loss: 1.535\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:32,866 - INFO - [1,  1300] loss: 1.522\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:33,149 - INFO - [1,  1300] loss: 1.549\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:35,120 - INFO - [1,  1400] loss: 1.546\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:35,513 - INFO - [1,  1400] loss: 1.569\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:37,809 - INFO - [1,  1500] loss: 1.520\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:37,965 - INFO - [1,  1500] loss: 1.554\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:39,370 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:39,504 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:44,828 - INFO - Accuracy of the network on the 10000 test images: 10.00 %\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:44,918 - INFO - Accuracy of the network on the 10000 test images: 10.00 %\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,103 - INFO - Delta_w: Max abs: 0.00044778932351619005, Min abs: 0.0, Median abs: 7.409714271489065e-06.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,105 - INFO - total params: 62006, epsilon: 0.1, perparam budget 1.7919220155538832e-06, threshold tau: 1e-06 + f(eps_1) = 8.680681153721836e-05, clip gamma: 1e-05\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,112 - INFO - selected 30619 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,115 - INFO - selected 46068 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,117 - INFO - selected 53993 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,118 - INFO - selected 57865 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,133 - INFO - noise max: 0.002093179280756597, median 0.00013979562231381966\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,158 - INFO - Delta_w: Max abs: 0.0005073346546851099, Min abs: 5.95855795260114e-11, Median abs: 7.293888302228879e-06.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,159 - INFO - total params: 62006, epsilon: 0.1, perparam budget 1.7919220155538832e-06, threshold tau: 1e-06 + f(eps_1) = 9.740573715018294e-05, clip gamma: 1e-05\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,166 - INFO - selected 30498 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,171 - INFO - selected 46008 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,173 - INFO - selected 53946 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,174 - INFO - selected 57957 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:45,183 - INFO - noise max: 0.0022137801075620025, median 0.0001380365327498202\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:46,089 - INFO - aggregating 2 update(s) at round 0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:46,092 - INFO - Start persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:46,095 - INFO - End persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:46,096 - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "                                Round 1 started.                                \n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:46,097 - INFO - Sampled clients: ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:46,097 - INFO - Sending task train to ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:47,615 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:47,616 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:47,616 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:47,617 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:47,843 - INFO - current_round=1, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:47,907 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:47,908 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:47,909 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:47,910 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:47,927 - INFO - current_round=1, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:50,109 - INFO - [1,   100] loss: 2.283\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:50,475 - INFO - [1,   100] loss: 2.291\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:52,457 - INFO - [1,   200] loss: 2.093\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:52,844 - INFO - [1,   200] loss: 2.115\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:55,016 - INFO - [1,   300] loss: 1.968\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:55,373 - INFO - [1,   300] loss: 1.947\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:57,723 - INFO - [1,   400] loss: 1.835\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:57,969 - INFO - [1,   400] loss: 1.866\u001b[0m\n",
      "\u001b[38m2025-10-26 18:02:59,948 - INFO - [1,   500] loss: 1.762\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:00,260 - INFO - [1,   500] loss: 1.784\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:02,213 - INFO - [1,   600] loss: 1.740\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:02,593 - INFO - [1,   600] loss: 1.688\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:04,863 - INFO - [1,   700] loss: 1.658\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:05,126 - INFO - [1,   700] loss: 1.681\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:07,251 - INFO - [1,   800] loss: 1.646\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:07,550 - INFO - [1,   800] loss: 1.622\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:09,766 - INFO - [1,   900] loss: 1.590\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:09,773 - INFO - [1,   900] loss: 1.610\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:12,094 - INFO - [1,  1000] loss: 1.575\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:12,441 - INFO - [1,  1000] loss: 1.607\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:14,571 - INFO - [1,  1100] loss: 1.553\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:14,888 - INFO - [1,  1100] loss: 1.567\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:17,116 - INFO - [1,  1200] loss: 1.552\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:17,543 - INFO - [1,  1200] loss: 1.557\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:19,559 - INFO - [1,  1300] loss: 1.517\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:19,936 - INFO - [1,  1300] loss: 1.542\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:21,902 - INFO - [1,  1400] loss: 1.548\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:22,316 - INFO - [1,  1400] loss: 1.524\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:24,314 - INFO - [1,  1500] loss: 1.475\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:24,621 - INFO - [1,  1500] loss: 1.481\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:25,857 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:26,100 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,480 - INFO - Accuracy of the network on the 10000 test images: 10.00 %\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,630 - INFO - Accuracy of the network on the 10000 test images: 10.00 %\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,701 - INFO - Delta_w: Max abs: 0.0003983148781117052, Min abs: 2.919693306568938e-11, Median abs: 6.874772225273773e-06.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,702 - INFO - total params: 62006, epsilon: 0.1, perparam budget 1.7919220155538832e-06, threshold tau: 1e-06 + f(eps_1) = -6.018655746009624e-05, clip gamma: 1e-05\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,709 - INFO - selected 31082 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,712 - INFO - selected 46738 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,714 - INFO - selected 54313 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,715 - INFO - selected 58237 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,724 - INFO - noise max: 0.0020107899550007593, median 0.00013952974839234454\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,765 - INFO - validation metric 10.0 from client site-2\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,970 - INFO - Delta_w: Max abs: 0.000503132410813123, Min abs: 1.7160646514913225e-10, Median abs: 6.603188921872061e-06.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,972 - INFO - total params: 62006, epsilon: 0.1, perparam budget 1.7919220155538832e-06, threshold tau: 1e-06 + f(eps_1) = -0.00013855292207587045, clip gamma: 1e-05\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,981 - INFO - selected 31471 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,985 - INFO - selected 47035 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,988 - INFO - selected 54604 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:31,990 - INFO - selected 58377 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:32,007 - INFO - noise max: 0.002761246428342801, median 0.00013764831342297326\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:32,065 - INFO - validation metric 10.0 from client site-1\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:32,340 - INFO - new best validation metric at round 1: 10.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:32,345 - INFO - aggregating 2 update(s) at round 1\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:32,348 - INFO - Start persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:32,351 - INFO - End persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:32,352 - INFO - \n",
      "--------------------------------------------------------------------------------\n",
      "                                Round 2 started.                                \n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:32,352 - INFO - Sampled clients: ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:32,353 - INFO - Sending task train to ['site-1', 'site-2']\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:34,071 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:34,072 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:34,072 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:34,074 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:34,139 - INFO - current_round=2, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:34,368 - INFO - execute for task (train)\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:34,369 - INFO - send data to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:34,370 - INFO - sending payload to peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:34,372 - INFO - Waiting for result from peer\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:34,502 - INFO - current_round=2, total_rounds=3\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:36,403 - INFO - [1,   100] loss: 2.237\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:37,546 - INFO - [1,   100] loss: 2.266\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:38,703 - INFO - [1,   200] loss: 2.045\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:40,082 - INFO - [1,   200] loss: 2.031\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:41,330 - INFO - [1,   300] loss: 1.931\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:42,818 - INFO - [1,   300] loss: 1.875\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:43,532 - INFO - [1,   400] loss: 1.824\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:45,522 - INFO - [1,   400] loss: 1.807\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:46,120 - INFO - [1,   500] loss: 1.732\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:48,038 - INFO - [1,   500] loss: 1.775\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:48,571 - INFO - [1,   600] loss: 1.699\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:50,398 - INFO - [1,   600] loss: 1.709\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:51,171 - INFO - [1,   700] loss: 1.693\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:52,882 - INFO - [1,   700] loss: 1.661\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:53,720 - INFO - [1,   800] loss: 1.673\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:55,245 - INFO - [1,   800] loss: 1.654\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:56,076 - INFO - [1,   900] loss: 1.653\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:57,933 - INFO - [1,   900] loss: 1.606\u001b[0m\n",
      "\u001b[38m2025-10-26 18:03:58,524 - INFO - [1,  1000] loss: 1.569\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:00,479 - INFO - [1,  1000] loss: 1.611\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:01,024 - INFO - [1,  1100] loss: 1.590\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:03,041 - INFO - [1,  1100] loss: 1.516\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:03,394 - INFO - [1,  1200] loss: 1.527\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:05,583 - INFO - [1,  1200] loss: 1.557\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:05,886 - INFO - [1,  1300] loss: 1.525\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:07,773 - INFO - [1,  1300] loss: 1.529\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:08,363 - INFO - [1,  1400] loss: 1.521\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:10,116 - INFO - [1,  1400] loss: 1.504\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:10,702 - INFO - [1,  1500] loss: 1.536\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:12,262 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:12,304 - INFO - [1,  1500] loss: 1.491\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:14,003 - INFO - Finished Training\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:18,484 - INFO - Accuracy of the network on the 10000 test images: 10.01 %\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:18,641 - INFO - Delta_w: Max abs: 0.00039869817555882037, Min abs: 2.979278768133753e-10, Median abs: 7.85706470196601e-06.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:18,644 - INFO - total params: 62006, epsilon: 0.1, perparam budget 1.7919220155538832e-06, threshold tau: 1e-06 + f(eps_1) = 9.116359947337331e-05, clip gamma: 1e-05\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:18,654 - INFO - selected 30647 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:18,660 - INFO - selected 46124 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:18,663 - INFO - selected 53940 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:18,665 - INFO - selected 57926 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:18,681 - INFO - noise max: 0.0022050826966178555, median 0.00013826212991633198\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:18,751 - INFO - validation metric 10.01 from client site-2\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,300 - INFO - Accuracy of the network on the 10000 test images: 10.01 %\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,430 - INFO - Delta_w: Max abs: 0.0004455511225387454, Min abs: 1.0248719234384751e-10, Median abs: 7.448959877365269e-06.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,431 - INFO - total params: 62006, epsilon: 0.1, perparam budget 1.7919220155538832e-06, threshold tau: 1e-06 + f(eps_1) = 0.00012429089116666546, clip gamma: 1e-05\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,438 - INFO - selected 30641 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,441 - INFO - selected 46080 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,444 - INFO - selected 53945 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,445 - INFO - selected 57954 responses, requested 55806.0\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,454 - INFO - noise max: 0.0022118504840267753, median 0.00013802511644627594\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,495 - INFO - validation metric 10.01 from client site-1\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,975 - INFO - new best validation metric at round 2: 10.01\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,978 - INFO - aggregating 2 update(s) at round 2\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,979 - INFO - Start persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,982 - INFO - End persist model on server.\u001b[0m\n",
      "\u001b[38m2025-10-26 18:04:19,982 - INFO - \n",
      "================================================================================\n",
      "                                Finished FedAvg.                                \n",
      "================================================================================\n",
      "\u001b[0m\n",
      "\u001b[33m2025-10-26 18:04:21,163 - WARNING - ask to stop job: reason: END_RUN received\u001b[0m\n",
      "\u001b[33m2025-10-26 18:04:21,498 - WARNING - request to stop the job for reason END_RUN received\u001b[0m\n",
      "\u001b[33m2025-10-26 18:04:21,788 - WARNING - ask to stop job: reason: END_RUN received\u001b[0m\n",
      "\u001b[33m2025-10-26 18:04:21,809 - WARNING - request to stop the job for reason END_RUN received\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "job.simulator_run(f\"/tmp/nvflare/{job.name}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31153,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
